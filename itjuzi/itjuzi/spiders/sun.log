2018-07-03 00:19:18 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: itjuzi)
2018-07-03 00:19:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:53:40) [MSC v.1500 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-10-10.0.17134
2018-07-03 00:19:18 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'itjuzi.spiders', 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['itjuzi.spiders'], 'BOT_NAME': 'itjuzi', 'COOKIES_ENABLED': False, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'sun.log', 'DOWNLOAD_DELAY': 1.5}
2018-07-03 00:19:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-07-03 00:19:18 [itjuzi] INFO: Reading start URLs from redis key 'itjuzispider:start_urls' (batch size: 16, encoding: utf-8
2018-07-03 00:19:18 [py.warnings] WARNING: E:\pythonProjects\guDemo\itjuzi\itjuzi\middlewares.py:9: ScrapyDeprecationWarning: Module `scrapy.contrib.downloadermiddleware.useragent` is deprecated, use `scrapy.downloadermiddlewares.useragent` instead
  from scrapy.contrib.downloadermiddleware.useragent import UserAgentMiddleware

2018-07-03 00:19:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'itjuzi.middlewares.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-03 00:19:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-03 00:19:18 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy_redis.pipelines.RedisPipeline']
2018-07-03 00:19:18 [scrapy.core.engine] INFO: Spider opened
2018-07-03 00:19:18 [twisted] CRITICAL: Unhandled error in Deferred:
2018-07-03 00:19:18 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "e:\python\python2\virtual\sc\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "e:\python\python2\virtual\sc\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "e:\python\python2\virtual\sc\lib\site-packages\scrapy\crawler.py", line 82, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
ResponseError: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
2018-07-03 12:14:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: itjuzi)
2018-07-03 12:14:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:53:40) [MSC v.1500 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-10-10.0.17134
2018-07-03 12:14:40 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'itjuzi.spiders', 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['itjuzi.spiders'], 'BOT_NAME': 'itjuzi', 'COOKIES_ENABLED': False, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'sun.log', 'DOWNLOAD_DELAY': 1.5}
2018-07-03 12:14:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-07-03 12:14:40 [itjuzi] INFO: Reading start URLs from redis key 'itjuzispider:start_urls' (batch size: 16, encoding: utf-8
2018-07-03 12:14:40 [py.warnings] WARNING: E:\pythonProjects\guDemo\itjuzi\itjuzi\middlewares.py:9: ScrapyDeprecationWarning: Module `scrapy.contrib.downloadermiddleware.useragent` is deprecated, use `scrapy.downloadermiddlewares.useragent` instead
  from scrapy.contrib.downloadermiddleware.useragent import UserAgentMiddleware

2018-07-03 12:14:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'itjuzi.middlewares.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-03 12:14:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-03 12:14:40 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy_redis.pipelines.RedisPipeline']
2018-07-03 12:14:40 [scrapy.core.engine] INFO: Spider opened
2018-07-03 12:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-03 12:14:40 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-03 12:14:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.itjuzi.com/user/login> (referer: None)
2018-07-03 12:14:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://www.itjuzi.com/user/login?redirect=&flag=&radar_coupon=> (referer: https://www.itjuzi.com/user/login)
2018-07-03 12:14:59 [itjuzi] DEBUG: Read 1 requests from 'itjuzispider:start_urls'
2018-07-03 12:15:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.itjuzi.com/company> from <GET http://www.itjuzi.com/company>
2018-07-03 12:15:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET http://radar.itjuzi.com/company> from <GET https://www.itjuzi.com/company>
2018-07-03 12:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://radar.itjuzi.com/company> (referer: None)
2018-07-03 12:15:32 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-07-03 12:15:32 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-07-03 12:15:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1619,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 4,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 10372,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/307': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 7, 3, 4, 15, 32, 649000),
 'log_count/DEBUG': 7,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued/redis': 5,
 'scheduler/enqueued/redis': 5,
 'start_time': datetime.datetime(2018, 7, 3, 4, 14, 40, 643000)}
2018-07-03 12:15:32 [scrapy.core.engine] INFO: Spider closed (shutdown)
2018-07-03 12:24:33 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: itjuzi)
2018-07-03 12:24:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:53:40) [MSC v.1500 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-10-10.0.17134
2018-07-03 12:24:33 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'itjuzi.spiders', 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['itjuzi.spiders'], 'BOT_NAME': 'itjuzi', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'sun.log', 'DOWNLOAD_DELAY': 1.5}
2018-07-03 12:24:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-07-03 12:24:33 [itjuzi] INFO: Reading start URLs from redis key 'itjuzispider:start_urls' (batch size: 16, encoding: utf-8
2018-07-03 12:24:33 [py.warnings] WARNING: E:\pythonProjects\guDemo\itjuzi\itjuzi\middlewares.py:9: ScrapyDeprecationWarning: Module `scrapy.contrib.downloadermiddleware.useragent` is deprecated, use `scrapy.downloadermiddlewares.useragent` instead
  from scrapy.contrib.downloadermiddleware.useragent import UserAgentMiddleware

2018-07-03 12:24:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'itjuzi.middlewares.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-03 12:24:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-03 12:24:33 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy_redis.pipelines.RedisPipeline']
2018-07-03 12:24:33 [scrapy.core.engine] INFO: Spider opened
2018-07-03 12:24:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-03 12:24:33 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-03 12:24:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.itjuzi.com/user/login> (referer: None)
2018-07-03 12:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://www.itjuzi.com/user/login?redirect=&flag=&radar_coupon=> (referer: https://www.itjuzi.com/user/login)
2018-07-03 12:24:55 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-07-03 12:24:55 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-07-03 12:24:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 865,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 8574,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 7, 3, 4, 24, 55, 954000),
 'log_count/DEBUG': 3,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued/redis': 2,
 'scheduler/enqueued/redis': 2,
 'start_time': datetime.datetime(2018, 7, 3, 4, 24, 33, 843000)}
2018-07-03 12:24:55 [scrapy.core.engine] INFO: Spider closed (shutdown)
2018-07-03 12:25:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: itjuzi)
2018-07-03 12:25:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 18.4.0, Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:53:40) [MSC v.1500 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-10-10.0.17134
2018-07-03 12:25:14 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'itjuzi.spiders', 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['itjuzi.spiders'], 'BOT_NAME': 'itjuzi', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'sun.log', 'DOWNLOAD_DELAY': 1.5}
2018-07-03 12:25:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-07-03 12:25:14 [itjuzi] INFO: Reading start URLs from redis key 'itjuzispider:start_urls' (batch size: 16, encoding: utf-8
2018-07-03 12:25:14 [py.warnings] WARNING: E:\pythonProjects\guDemo\itjuzi\itjuzi\middlewares.py:9: ScrapyDeprecationWarning: Module `scrapy.contrib.downloadermiddleware.useragent` is deprecated, use `scrapy.downloadermiddlewares.useragent` instead
  from scrapy.contrib.downloadermiddleware.useragent import UserAgentMiddleware

2018-07-03 12:25:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'itjuzi.middlewares.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-03 12:25:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-03 12:25:14 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy_redis.pipelines.RedisPipeline']
2018-07-03 12:25:14 [scrapy.core.engine] INFO: Spider opened
2018-07-03 12:25:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-03 12:25:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-03 12:25:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.itjuzi.com/user/login> (referer: None)
2018-07-03 12:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://www.itjuzi.com/user/login?redirect=&flag=&radar_coupon=> (referer: https://www.itjuzi.com/user/login)
2018-07-03 12:25:43 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-07-03 12:25:43 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-07-03 12:25:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 848,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 8576,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 7, 3, 4, 25, 43, 981000),
 'log_count/DEBUG': 3,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued/redis': 2,
 'scheduler/enqueued/redis': 2,
 'start_time': datetime.datetime(2018, 7, 3, 4, 25, 14, 474000)}
2018-07-03 12:25:43 [scrapy.core.engine] INFO: Spider closed (shutdown)
